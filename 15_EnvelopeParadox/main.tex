You are presented with two identical envelopes — you are told that one envelope contains twice the money as the other. No other information is given. You select one envelope at random and open it, revealing \$100. At this point, you are given the opportunity to switch.

Consider the reasoning that leads to paradox. The envelope you opened contains \$100, which must be either the smaller amount or the larger. If \$100 is the smaller amount, the other envelope contains \$200. If \$100 is the larger amount, the other envelope contains \$50. Since these two cases seem equally likely, the expected value from switching appears to be:
\[
\text{Expected gain} = 0.5 \cdot (+100) + 0.5 \cdot (-50) = +25.
\]
This suggests a \$25 gain from switching. The same calculation applies regardless of the amount observed, whether \$10, \$100, or \$1000. You should apparently switch every time. But this logic also tells you to switch back again after switching, producing an endless preference loop. The contradiction is that each envelope appears preferable to the other.

Why does this reasoning feel compelling? The calculation follows expected value logic. The probabilities seem reasonable. Without additional information, why shouldn't the observed amount be equally likely to be the smaller or larger? The arithmetic is correct. Yet the conclusion violates intuitions about symmetric problems. The puzzle demands a definitive answer while generating contradictory recommendations.

The error lies in how the observed amount $x$ is interpreted across different terms of the expectation. In one term, $x$ represents the smaller amount; in the other, it represents the larger amount. This reference creates incompatible baselines for comparison.

To make the model coherent, let \( x \) denote the smaller of the two amounts. Then the envelopes contain \( x \) and \( 2x \), and each is equally likely to be selected. If you hold \( x \), switching yields \( +x \); if you hold \( 2x \), switching yields \( -x \). The outcomes cancel:
\[
\text{Average change} = 0.5 \cdot (+x) + 0.5 \cdot (-x) = 0.
\]
No advantage arises. The paradox dissolves because the original argument uses expectation without a consistent model.

This becomes clearer in a bounded setup. Suppose the smaller amount is chosen uniformly from \( \{2^0, 2^1, \dots, 2^{999}\} \). For most observed amounts \( A \), switching seems to yield a gain of \( +0.25A \) since \( A \) could be either the smaller or larger envelope value. However, this ignores boundary cases: if \( A = 2^0 \), switching cannot halve it; if \( A = 2^{999} \), switching cannot double it. These rare but extreme boundary effects precisely cancel the average gain across interior values, returning the total expectation to zero.

In the limit as the model becomes unbounded, for example, when \( x \) is drawn from \( \{\dots, 2^{-2}, 2^{-1}, 2^0, 2^1, \dots\} \), the problem reappears. For any observed amount, switching appears to yield a gain of \( +0.25A \). But this assumes all values are equally probable, which is not possible over an infinite set.

A uniform distribution over an infinite number of values cannot exist — there is no way to assign equal, nonzero probability to infinitely many outcomes and still have the total probability equal to one. Any attempt results in an \emph{improper prior}: a function that resembles a distribution but cannot be normalized.

To reason coherently in such a context, one must use a \emph{probability measure}: a rule that assigns consistent, additive weights to sets of values and sums to one. A measure is \emph{proper} if it satisfies this condition. If it diverges or is undefined, expectations may not exist. Even if each outcome is finite, the global average may be infinite or ill-defined. In that case, expectation ceases to be a meaningful decision tool.

One setup does yield a switching advantage. Fix a value \( a \) and flip a coin: if heads, prepare envelopes with \( a \) and \( 2a \); if tails, use \( a \) and \( a/2 \). Hand the envelope containing \( a \) to the player. Switching yields either \( +a \) or \( -0.5a \) with equal probability, giving an expected gain of \( +0.25a \). Here, switching is optimal because the model is asymmetric and expectation is applied with explicit conditioning. The contrast reveals that expectation requires consistent reference frames, not just surface-level calculations.

The distinction between these cases highlights an issue in decision theory — \textbf{what information do you actually possess?} In the standard envelope paradox, you observe an amount but know nothing about how envelope pairs are generated. In the coin-flip variant, you know the generation process but not which envelope you hold. This difference in information setup determines whether switching is advantageous.

The switching advantage depends entirely on the unknown prior distribution over envelope pairs. If smaller amounts are more probable, observing \$100 suggests you likely hold the larger envelope. If larger amounts are more probable, the reverse holds. Without knowing this distribution, rational choice becomes impossible.

This connects to \textbf{Bertrand's paradox} and other information-dependent problems in probability theory. The "principle of indifference" fails when the reference class is ambiguous, as it treats outcomes as equally likely in the absence of information. Should you treat $(50, 100)$ and $(100, 200)$ as equally likely pairs? Or should you treat amounts \$50, \$100, \$200 as equally likely? The choice of reference class determines the answer.

The envelope paradox reveals issues in rational choice theory. \textbf{Dominance arguments}, the idea that one option should be preferred if it yields better outcomes in every possible state, break down when the state space itself depends on the choice. \textbf{Dynamic consistency}, maintaining the same preferences over time as information is revealed, becomes problematic when the information setup is unclear.

Resolution requires specifying what counts as a decision problem. The \textbf{Bayesian approach} demands a prior distribution over envelope pairs; once specified, the switching advantage can be calculated exactly. The \textbf{information-theoretic approach} notes that in symmetric setups, observation carries no information about relative position, so switching provides no advantage. The \textbf{frequentist approach} shows that over many trials with a fixed distribution, switching yields no net gain. The \textbf{pragmatic approach} acknowledges that if the generation process is unknowable, the decision lacks sufficient structure for rational analysis. The paradox reveals tensions between intuitive reasoning and formal analysis, highlighting the limits of decision theory when information is incomplete.


\begin{commentary}[Reasoning with and around Paradoxes]
Probability paradoxes often arise from extending otherwise reliable tools, such as symmetry, expectation, or conditional likelihood, beyond the domains where they are mathematically coherent. Once the generative assumptions are clarified, the contradiction typically disappears.

Analytical resolution involves selecting a valid prior over the smaller amount and computing the conditional expectation given the observed value. But intuition often fails before analysis begins. The paradox feels persuasive because it aligns with a mental shortcut: the imagined gain from doubling exceeds the loss from halving. Moreover, simulations over bounded ranges frequently reproduce this 25\% average gain in the interior of the distribution, while obscuring the boundary corrections that neutralize the effect.

A complementary tool is empirical. By simulating the game with a finite model, such as drawing $x$ from a list of powers of two, one can directly compare switching and staying strategies:

\begin{verbatim}
import random

base = [2**i for i in range(30)]  # bounded distribution

def switch_strategy():
    x = random.choice(base)
    amount = random.choice([x, 2*x])
    # Faulty logic: assumes unbounded doubling/halving
    return 2 * amount if amount == x else amount / 2

def no_switch_strategy():
    x = random.choice(base)
    return random.choice([x, 2*x])

# Run simulation (n = 10^6)
switch_avg = sum(switch_strategy() for _ in range(10**6)) / 10**6
stay_avg = sum(no_switch_strategy() for _ in range(10**6)) / 10**6
\end{verbatim}

The switching strategy appears advantageous, but only because it violates the constraint that envelope pairs must come from the predefined base set. Switching from \( 2^{29} \) yields \( 2^{30} \), even though that value was not part of the original distribution.

To resolve the paradox, add proper boundary checking:

\begin{verbatim}
# Correct switching with bounds
if amount == x:  # smaller value
    new = 2 * amount
    return new if new in base else amount
else:  # larger value  
    new = amount // 2
    return new if new in base else amount
\end{verbatim}

With this correction, the switching advantage disappears entirely. The simulation confirms the formal result: in a symmetric, finite model, switching yields no net gain once edge conditions are treated correctly.

Simulation is not a substitute for proof, yet it helps clarify where the paradox gains its force.

\end{commentary}