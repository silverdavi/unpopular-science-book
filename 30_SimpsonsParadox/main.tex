In North Carolina's 2012 congressional elections, Democratic candidates received 51\% of votes statewide yet won only 4 of 13 seats. Republicans secured 9 seats with 49\% of votes. No voting machines malfunctioned. No ballots were miscounted. The reversal occurred through district boundaries — lines drawn to group voters in ways that inverted the relationship between votes and representation.

Statistical association hinges on how data are grouped. The same population can yield opposite conclusions depending on the partition chosen. In extreme cases, a relationship positive in every subgroup becomes negative when groups combine — or a democratic majority becomes a legislative minority through strategic line-drawing.

Simpson's paradox exemplifies accidental reversal. A kidney stone treatment shows 93\% success for small stones and 73\% for large stones. A competing treatment achieves only 87\% for small stones and 69\% for large stones. The first treatment beats the second in both categories. Yet overall success rates reverse: 79\% versus 85.5\%. The paradox arises because doctors used the superior treatment primarily on difficult cases — 70\% of its patients had large stones, while 91\% of the inferior treatment's patients had small stones.

Gerrymandering engineers deliberate reversal. Wisconsin's 2012 state assembly elections saw Democrats win 53\% of votes but only 39\% of seats. The mechanism: district lines packed Democratic voters into urban districts where they won by 70-80\% margins, while Republican victories spread efficiently across suburban and rural districts with 55-60\% margins. Both phenomena — Simpson's paradox and gerrymandering — exploit the mathematics of aggregation, but with opposite intent. The mathematics underlying both phenomena reduces to weighted averages. When calculating any aggregate statistic — whether treatment success rates or electoral outcomes — the result depends on two factors: the values within each group and the relative sizes of groups. Change either factor and the aggregate shifts.

In formal terms, if groups have success rates $p_1, p_2, ..., p_k$ and sizes $n_1, n_2, ..., n_k$, the overall rate is:
\[
\bar{p} = \frac{\sum_{i=1}^k n_i p_i}{\sum_{i=1}^k n_i}
\]
Simpson's paradox occurs when natural imbalances in group sizes $(n_i)$ cause $\bar{p}$ to misrepresent the relationship seen in individual $p_i$ values. Gerrymandering manipulates the same formula by choosing group boundaries to engineer specific $(n_i)$ values.

The kidney stone example illustrates the reversal:

\begin{center}
\begin{tabular}{lccc}
\toprule
 & Success Rate & Patients & Successes \\
\midrule
Treatment A, Small stones & 93\% & 30 & 28 \\
Treatment B, Small stones & 87\% & 200 & 174 \\
Treatment A, Large stones & 73\% & 70 & 51 \\
Treatment B, Large stones & 69\% & 20 & 14 \\
\midrule
Treatment A, Overall & 79\% & 100 & 79 \\
Treatment B, Overall & 85.5\% & 220 & 188 \\
\bottomrule
\end{tabular}
\end{center}

Treatment A wins in both stone categories yet loses overall. The reversal mechanism: unequal group distributions. Treatment A handled 70\% difficult cases (large stones), Treatment B only 9\%. When groups combine, Treatment B's easy-case bias overwhelms its inferior performance.

Gerrymandering employs identical mathematics with opposite intent. Consider a simplified state with 10 districts, 5 million voters split evenly between parties:

\begin{center}
\begin{tabular}{lcc}
\toprule
Districting Strategy & Party A Seats & Party B Seats \\
\midrule
Proportional (each district 50-50) & 5 & 5 \\
Gerrymandered for A & 7 & 3 \\
Gerrymandered for B & 3 & 7 \\
\bottomrule
\end{tabular}
\end{center}

The gerrymandered scenarios achieve 70\% of seats with 50\% of votes by controlling group boundaries. Party A might pack Party B voters into 3 districts where B wins 80-20, then spread remaining voters to secure 7 districts with 56-44 margins. Same voters, same preferences, inverted outcome.

The UC Berkeley admissions case (1973) demonstrated accidental grouping effects. Women showed lower overall acceptance rates (35\%) than men (44\%), suggesting discrimination. Department-level analysis revealed the opposite: women had equal or higher acceptance rates in 4 of 6 departments. The reversal occurred because women disproportionately applied to competitive departments — English admitted 3.4\% of applicants while Engineering admitted 65\%. Group imbalance, not bias, created the aggregate disparity.

The distinction between Simpson's paradox and gerrymandering crystallizes through intent and control:

\textbf{Simpson's Paradox}: Natural groupings create misleading aggregates
\begin{itemize}
\item Doctors assign treatments based on medical judgment
\item Students choose departments based on interests
\item Platform users select devices based on preferences
\item Groups form organically; reversals surprise analysts
\end{itemize}

\textbf{Gerrymandering}: Artificial groupings engineer specific aggregates
\begin{itemize}
\item Politicians draw district lines to maximize seats
\item Boundaries split communities to dilute opposition votes
\item Sophisticated algorithms optimize "wasted" votes
\item Groups form strategically; reversals are the goal
\end{itemize}

Both exploit the gap between local and global measures. In Simpson's paradox, local measures (department-specific admission rates) tell the truth while global measures (overall rates) mislead. In gerrymandering, local measures (district-level victories) are manipulated to distort global truth (statewide voter preference).

The mathematical machinery operates identically in both cases. For any partition of data into groups, the overall average equals:
\[
\bar{y} = \sum_{i} w_i \bar{y}_i
\]
where $w_i = n_i/N$ represents the fraction of data in group $i$, and $\bar{y}_i$ is that group's average. The weights $w_i$ determine everything. Change the weights, change the conclusion.

Simpson's paradox: weights arise from existing patterns (sick patients get aggressive treatment)
Gerrymandering: weights are engineered through boundaries (opposition voters get packed or cracked)

The efficiency gap quantifies gerrymandering's success by measuring "wasted" votes — those beyond the 50\%+1 needed to win a district. A party that wins districts by slim margins while losing others by wide margins achieves maximum efficiency. The formula:
\[
\text{Efficiency Gap} = \frac{|\text{Wasted}_A - \text{Wasted}_B|}{\text{Total Votes}}
\]
Values above 7\% typically indicate intentional manipulation rather than natural geographic clustering.

Real-world detection differs sharply between the phenomena:

Simpson's paradox emerges through analysis. Statisticians discover reversals by examining subgroups, often surprised by the findings. The 2020 COVID-19 case fatality rates showed Italy with higher death rates than China overall, yet lower rates in every age group — Italy's older population created the reversal. Discovery prompts deeper investigation into confounding variables.

Gerrymandering leaves fingerprints. Districts snake through neighborhoods, splitting cities and joining disparate communities. Pennsylvania's 7th district (pre-2018) stretched like tentacles across five counties to link Republican areas while avoiding Democratic ones. Mathematical tests expose the manipulation: efficiency gaps exceeding natural variation, districts with fractal-like perimeters, and seat allocations that defy probabilistic models of random districting.

Both phenomena reveal a fundamental truth: data interpretation depends on boundaries. Simpson's paradox warns that natural boundaries (patient severity, department selectivity) can mislead when ignored. Gerrymandering demonstrates that artificial boundaries can be weaponized to subvert democratic representation.

The solution to Simpson's paradox: disaggregate data and examine subgroups. Medical trials now routinely report results by patient characteristics. Universities analyze admissions by department. The goal is transparency — revealing how aggregation affects conclusions.

The solution to gerrymandering requires structural reform: independent redistricting commissions, mathematical constraints on district compactness, or algorithmic districting that minimizes partisan advantage. Several states now use efficiency gap calculations in legal challenges to districting plans.

Data's meaning depends on its divisions. Whether those divisions arise naturally or through manipulation, they determine what stories the numbers tell. Understanding this principle — that the same data can support opposite conclusions through different groupings — becomes essential for interpreting everything from medical research to election results.


\vspace*{\fill}

\clearpage



\begin{center}
{\Large \textbf{More Statistical Paradoxes and Interpretation Failures}}

\end{center}

\vspace{1em}

\begin{tcolorbox}[
  colback=gray!2,
  colframe=gray!60,
  boxrule=0.4pt,
  width=\textwidth,
  arc=1pt,
  left=8pt,
  right=8pt,
  top=6pt,
  bottom=6pt,
  shadow={0mm}{-0.5mm}{0mm}{gray!30}
]
\setstretch{1}

\textbf{1. Berkson’s Paradox}  
\emph{Conditioning on a common effect induces spurious negative correlation.}  
If two independent variables both affect a selection criterion, then restricting attention to cases that satisfy that criterion creates an artificial negative correlation. This occurs in hospital datasets, where independent risk factors may appear inversely related when conditioned on admission. The association is real in the conditional data but does not reflect a relationship in the population.

\vspace{1em}

\textbf{2. Ecological Fallacy}  
\emph{Group-level associations are wrongly projected onto individuals.}  
When a statistical association holds across aggregated units — such as regions or schools — it does not necessarily hold within them. For example, a country with higher average education may have higher average income, but this does not imply that more educated individuals earn more within each region. Unlike Simpson’s paradox, ecological fallacy involves misapplying group-level trends to individual inference without requiring any reversal. The error lies in cross-level extrapolation, not confounding.

\vspace{1em}

\textbf{3. Will Rogers Phenomenon}  
\emph{Reclassification improves group averages without improving any member.}  
If individuals from the low end of one group are reclassified into another group with even lower average, both groups may show improved mean outcomes. This occurs in cancer staging and school performance tracking, and reflects the fact that averages are sensitive to how groups are defined — even when no unit changes.

\vspace{1em}

\textbf{4. Modifiable Areal Unit Problem (MAUP)}  
\emph{Statistical results depend on the choice of spatial or administrative boundaries.}  
In spatial analysis, correlations and rates can shift significantly depending on how geographic regions are aggregated. A pattern observed at the county level may not hold at the district level or when boundaries are redrawn.

\vspace{1em}

\textbf{5. Low Birth-Weight Paradox}  
\emph{Conditioning on an intermediate variable reverses risk comparisons.}  
Infants born to smoking mothers have higher rates of low birth weight, and low birth weight is associated with higher mortality. But among low birth-weight babies, those born to smokers may show lower mortality than those of non-smokers. The paradox emerges because birth weight is both an effect of smoking and a predictor of mortality. Conditioning on it introduces collider bias, obscuring causal direction.

\vspace{1em}

\textbf{6. Prosecutor’s Fallacy}  
\emph{Confusing the likelihood of evidence with the probability of guilt.}  
In forensic contexts, the probability of observing the evidence assuming innocence is often mistaken for the probability of innocence given the evidence. For example, a DNA match with a false positive rate of $1/1000$ is incorrectly interpreted as implying a $0.1\%$ chance of innocence, ignoring base rates. The fallacy reflects improper inversion of conditional probability.

\end{tcolorbox}

